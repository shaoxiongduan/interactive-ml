{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install torch torchvision numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader,Dataset\n",
    "import torchvision.transforms as T\n",
    "import os\n",
    "import gzip\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNISTDataset(Dataset):\n",
    "    def __init__(self,datadir,transform,is_train = True):\n",
    "        super().__init__()\n",
    "        self.datadir = datadir\n",
    "        self.img,self.label = self.load_data(self.datadir, is_train = is_train)\n",
    "        self.len_data = len(self.img)\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __getitem__(self,index):\n",
    "        return self.transform(self.img[index]), self.label[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.len_data\n",
    "    \n",
    "    def load_data(self, datadir, is_train):\n",
    "        dirname = os.path.join(datadir)\n",
    "        files = ['train-labels-idx1-ubyte.gz', 'train-images-idx3-ubyte.gz',\n",
    "            't10k-labels-idx1-ubyte.gz', 't10k-images-idx3-ubyte.gz']\n",
    "\n",
    "        paths = []\n",
    "        for fname in files:\n",
    "            paths.append(os.path.join(dirname,fname))\n",
    "        if is_train:\n",
    "\n",
    "            with gzip.open(paths[0], 'rb') as lbpath:\n",
    "                label = np.frombuffer(lbpath.read(), np.uint8, offset=8)\n",
    "            with gzip.open(paths[1], 'rb') as imgpath:\n",
    "                img = np.frombuffer(imgpath.read(), np.uint8,\n",
    "                                   offset=16).reshape(len(label), 28, 28)\n",
    "        else:\n",
    "            with gzip.open(paths[2], 'rb') as lbpath:\n",
    "                label = np.frombuffer(lbpath.read(), np.uint8, offset=8)\n",
    "\n",
    "            with gzip.open(paths[3], 'rb') as imgpath:\n",
    "                img = np.frombuffer(imgpath.read(), np.uint8,\n",
    "                                      offset=16).reshape(len(label), 28, 28)\n",
    "        return img, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 28, 28])\n",
      "5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torchvision/transforms/functional.py:154: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_numpy.cpp:212.)\n",
      "  img = torch.from_numpy(pic.transpose((2, 0, 1))).contiguous()\n"
     ]
    }
   ],
   "source": [
    "\"\"\"MNIST数据集\"\"\"\n",
    "train_dataset = MNISTDataset(\n",
    "    datadi = 'MNIST/raw',\n",
    "    transform = T.ToTensor(),\n",
    "    is_train = True\n",
    ")\n",
    "test_dataset = MNISTDataset(\n",
    "    datadir = 'MNIST/raw',\n",
    "    transform = T.ToTensor(),\n",
    "    is_train = False\n",
    ")\n",
    "# DataLoader\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, drop_last=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=10000, shuffle=False, drop_last=False)\n",
    "data,target = train_dataset[0]\n",
    "print(data.shape)\n",
    "print(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(28*28, 128)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.fc3 = nn.Linear(64, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        x = self.relu1(self.fc1(x))\n",
    "        x = self.relu2(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SimpleNN() # 实例化模型\n",
    "loss_fn = nn.CrossEntropyLoss() # 损失函数：交叉熵损失\n",
    "opt = torch.optim.Adam(model.parameters(),lr=1e-3) # 定义优化器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''训练代码'''\n",
    "def train(epoch):\n",
    "    model.train()\n",
    "    total_loss = 0.\n",
    "    for iter,(data,target) in enumerate(train_loader):\n",
    "        opt.zero_grad()  # backward前梯度清零\n",
    "        output = model(data)\n",
    "        loss = loss_fn(output,target) # 计算损失\n",
    "        loss.backward() # 误差反向传播，计算梯度\n",
    "        opt.step() # 参数更新\n",
    "        total_loss += loss.item()\n",
    "    print(f'Train Epoch: {epoch} Loss: {total_loss/len(train_loader):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''测试代码'''\n",
    "def test(epoch):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    tot = 0\n",
    "    for data,target in test_loader:\n",
    "        output = model(data)\n",
    "        # 使用for循环找到每个输出的最大值对应的索引（即预测的类别）\n",
    "        pred = []\n",
    "        for i in range(output.size(0)):  # 遍历每个样本\n",
    "            max_index = 0\n",
    "            max_value = output[i][0]\n",
    "            for j in range(1, output.size(1)):  # 遍历每个类别的得分\n",
    "                if output[i][j] > max_value:\n",
    "                    max_value = output[i][j]\n",
    "                    max_index = j\n",
    "            pred.append(max_index)\n",
    "        \n",
    "        # 使用for循环计算正确预测的数量\n",
    "        for i in range(len(pred)):\n",
    "            if pred[i] == target[i]:\n",
    "                correct += 1\n",
    "        \n",
    "        tot+=data.shape[0]\n",
    "\n",
    "    print(f'Test Epoch:{epoch} Accuracy: {correct/tot*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0 Loss: 2.269\n",
      "Test Epoch:0 Accuracy: 33.06%\n",
      "Train Epoch: 1 Loss: 2.141\n",
      "Test Epoch:1 Accuracy: 51.49%\n",
      "Train Epoch: 2 Loss: 1.848\n",
      "Test Epoch:2 Accuracy: 67.73%\n",
      "Train Epoch: 3 Loss: 1.341\n",
      "Test Epoch:3 Accuracy: 77.19%\n",
      "Train Epoch: 4 Loss: 0.913\n",
      "Test Epoch:4 Accuracy: 82.37%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for epoch in range(5):\n",
    "    '''训练'''\n",
    "    train(epoch)\n",
    "    '''测试'''\n",
    "    test(epoch)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
