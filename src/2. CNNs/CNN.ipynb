{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torchvision/transforms/functional.py:154: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_numpy.cpp:212.)\n",
      "  img = torch.from_numpy(pic.transpose((2, 0, 1))).contiguous()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 0.4289\n",
      "Epoch [2/10], Loss: 0.2752\n",
      "Epoch [3/10], Loss: 0.2291\n",
      "Epoch [4/10], Loss: 0.1952\n",
      "Epoch [5/10], Loss: 0.1685\n",
      "Epoch [6/10], Loss: 0.1465\n",
      "Epoch [7/10], Loss: 0.1252\n",
      "Epoch [8/10], Loss: 0.1057\n",
      "Epoch [9/10], Loss: 0.0877\n",
      "Epoch [10/10], Loss: 0.0718\n",
      "Accuracy on test set: 91.97%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import os\n",
    "import gzip\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load and preprocess the FashionMNIST dataset\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "class MNISTDataset(Dataset):\n",
    "    def __init__(self,datadir,transform,is_train = True):\n",
    "        super().__init__()\n",
    "        self.datadir = datadir\n",
    "        self.img,self.label = self.load_data(self.datadir, is_train = is_train)\n",
    "        self.len_data = len(self.img)\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __getitem__(self,index):\n",
    "        return self.transform(self.img[index]), self.label[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.len_data\n",
    "    \n",
    "    def load_data(self, datadir, is_train):\n",
    "        dirname = os.path.join(datadir)\n",
    "        files = ['train-labels-idx1-ubyte.gz', 'train-images-idx3-ubyte.gz',\n",
    "            't10k-labels-idx1-ubyte.gz', 't10k-images-idx3-ubyte.gz']\n",
    "\n",
    "        paths = []\n",
    "        for fname in files:\n",
    "            paths.append(os.path.join(dirname,fname))\n",
    "        if is_train:\n",
    "            with gzip.open(paths[0], 'rb') as lbpath:\n",
    "                label = np.frombuffer(lbpath.read(), np.uint8, offset=8)\n",
    "            with gzip.open(paths[1], 'rb') as imgpath:\n",
    "                img = np.frombuffer(imgpath.read(), np.uint8,\n",
    "                                   offset=16).reshape(len(label), 28, 28)\n",
    "        else:\n",
    "            with gzip.open(paths[2], 'rb') as lbpath:\n",
    "                label = np.frombuffer(lbpath.read(), np.uint8, offset=8)\n",
    "            with gzip.open(paths[3], 'rb') as imgpath:\n",
    "                img = np.frombuffer(imgpath.read(), np.uint8,\n",
    "                                      offset=16).reshape(len(label), 28, 28)\n",
    "        return img, label\n",
    "\n",
    "# Load the datasets with the provided code\n",
    "train_dataset = MNISTDataset(\n",
    "    datadir='FashionMNIST/raw',\n",
    "    transform=transform,\n",
    "    is_train=True\n",
    ")\n",
    "test_dataset = MNISTDataset(\n",
    "    datadir='FashionMNIST/raw',\n",
    "    transform=transform,\n",
    "    is_train=False\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the CNN architecture\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.fc1 = nn.Linear(64 * 7 * 7, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(self.relu(self.conv1(x)))\n",
    "        x = self.pool(self.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 64 * 7 * 7)\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model, loss function, and optimizer\n",
    "model = CNN().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        \n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader):.4f}\")\n",
    "\n",
    "# Evaluation\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f\"Accuracy on test set: {100 * correct / total:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
